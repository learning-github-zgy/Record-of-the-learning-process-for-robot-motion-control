传统的机械臂控制是 IK，机器人是 MPC 和零力矩点控制；<br />目前有很多利用强化学习、模仿学习进、扩散模型进行仿真再 sim to real 进行控制。<br />这个在读博士总结的很全面，因为他也是从传统控制一步步走到现在强化学习的路上<br />[四/双足机器人的运动规划与控制：一个在读PhD的阶段性回顾 - 知乎](https://zhuanlan.zhihu.com/p/658133852)
<a name="fRWLz"></a>
# 八股
<a name="GyyjG"></a>
## 计算机自学指南
[CS自学指南](https://csdiy.wiki/)北大计算机同学写的计算机学习路线以及优质的课程内容，方便进行学习。

<a name="dIof3"></a>
## 角色动画
games105 课程：[Lecture03 Character Kinematics: Forward and Inverse Kinematics_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1GG4y1p7fF?p=3&vd_source=32aee7e160efdea3b1422dda7cc2726a)<br />里面有很多 IK 和重定向的基础知识，常看常新<br />评论总结的 PDF：[foocker/CharacterAnimation](https://github.com/foocker/CharacterAnimation)<br />[CharacterAnimation.pdf](https://www.yuque.com/attachments/yuque/0/2024/pdf/39264174/1718609713267-62d61d0b-5216-47a9-bbfb-403a6a33edac.pdf)
<a name="q91j3"></a>
## 强化学习数学原理
[【强化学习的数学原理】课程：从零开始到透彻理解（完结）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1sd4y167NS/?spm_id_from=333.999.0.0&vd_source=288648f5b920459d12ebbcfd2da00a19)<br />github 地址：[MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning: This is the homepage of a new book entitled "Mathematical Foundations of Reinforcement Learning."](https://github.com/MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning)<br />里面有 pdf 版本介绍各个章节，常看这个可以了解强化学习的数学公式！
<a name="LShtD"></a>
## OpenAI 的 Spinning Up
[Welcome to Spinning Up in Deep RL! — Spinning Up documentation](https://spinningup.openai.com/en/latest/index.html)
<a name="wfNi8"></a>
### 强化学习的关键概念
在 RL 中策略通常决定在给定状态下的应该采取什么动作，策略的输出可以是确定的动作，策略可以输出一个概率分布，即均值和标准差，这里的概率分布式多元高斯分布，每个动作都有独立的均值和标准差，这里的标准差是对数标准差，因为 log 函数的范围是正负无穷，标准差是非负，刚好可以讲标准差映射到实数范围。当智能体采取动作时，需要从输出的分布中进行采样，采样的公式为：![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720162729069-8b095f6e-8d2b-470e-8971-363fcff53259.png#averageHue=%23eae9ea&clientId=u199fa52e-79a9-4&from=paste&height=34&id=u1e117040&originHeight=34&originWidth=196&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1854&status=done&style=none&taskId=ua80b0932-80d4-4f64-841d-949e102ed33&title=&width=196)其中 z 为噪声，为了增加鲁棒性以及探索更多的可能性，输出的标准差与球形高斯噪声相乘。<br />在策略输出概率分布之后，对数似然可以计算当前的动作与期望的动作之间的差异，其中第一项表示当前的动作与输出概率分布之间的差异。通过调整对数似然估计来调整其中的参数，使策略更新的时候朝向提高采样动作概率的方向进行，从而增加高回报动作的概率，这里的采样动作是具有高 reward 的样本空间。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720163248181-4383e526-78d8-425d-ab26-778f6b0a7d67.png#averageHue=%23ebeaeb&clientId=u199fa52e-79a9-4&from=paste&height=83&id=u749a7482&originHeight=83&originWidth=492&originalType=binary&ratio=1&rotation=0&showTitle=false&size=6726&status=done&style=none&taskId=u126bb177-f9e3-4cc3-bf6d-443473b456a&title=&width=492)<br />轨迹是一系列状态和动作，通常还被称为 episode 和 rollouts。<br />价值函数和动作价值函数之间有一定的关联：第一个公式：价值函数等于动作价值函数的期望，因为在当前状态下采取所有的动作计算的汇报再求期望就是等于在该装状态下的指函数；同理第二个公式：最优值函数等于最大的最优动作值函数，因为最优的动作值函数等于在当前状态下采取动作的最大汇报，那么我取最大值就是当前状态下的最大汇报了，也就是最优值函数。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720167144092-02c813c7-c7e8-4767-b9e1-83683ed6808a.png#averageHue=%23ebeaeb&clientId=u199fa52e-79a9-4&from=paste&height=120&id=u968ea9de&originHeight=120&originWidth=211&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4621&status=done&style=none&taskId=u0e0bea13-6c05-4839-b1c3-77c023ba372&title=&width=211)<br />贝尔曼方程思想：出发点的 reward 就是一开始的奖励加上接下来达到点的奖励。<br />可以看到值函数的贝尔曼方程和动作价值函数的贝尔曼方程之间的关系，再结合值函数和动作价值函数就可以很清楚的看出动作价值函数的第二项就是在状态 s'的值函数。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720167869135-90e0c8ed-b332-4cd7-8c3e-c4de744c78bf.png#averageHue=%23f4f4f4&clientId=u199fa52e-79a9-4&from=paste&height=112&id=u712af4b7&originHeight=112&originWidth=366&originalType=binary&ratio=1&rotation=0&showTitle=false&size=6670&status=done&style=none&taskId=u3fb3c675-c080-49d2-b010-df0e92cca37&title=&width=366)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720167877890-29ea051a-f75e-47d7-9a02-da838ea3ea44.png#averageHue=%23f4f4f4&clientId=u199fa52e-79a9-4&from=paste&height=100&id=ufe5db107&originHeight=100&originWidth=377&originalType=binary&ratio=1&rotation=0&showTitle=false&size=6542&status=done&style=none&taskId=u0f937480-c701-4441-99e9-53cf63caeb8&title=&width=377)<br />Bellman backup 是贝尔曼方程的右侧，就当前的奖励家还是那个下一个奖励。<br />优势函数：描述选择该动作比另一个动作好多少![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720168496822-81e799b5-212c-478a-9349-deedca5f3767.png#averageHue=%23f5f5f5&clientId=u199fa52e-79a9-4&from=paste&height=51&id=uefce5d6f&originHeight=51&originWidth=263&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2262&status=done&style=none&taskId=ucd1ce1fa-a53f-4c57-8731-ef9775f639f&title=&width=263)<br />马尔可夫决策过程：状态转移只取决于当前的状态和动作，与之前的状态和动作无关。
<a name="wuL8c"></a>
### 强化学习算法的分类
![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720168563594-02bf24f7-1e08-46ae-9e56-e0d6ef4b3ec5.png#averageHue=%2325201b&clientId=u199fa52e-79a9-4&from=paste&height=511&id=ud634a13e&originHeight=511&originWidth=987&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53709&status=done&style=none&taskId=ub150f1c6-a57a-4490-beab-473d8a1cc0b&title=&width=987)<br />有无模型的区别在于是否拥有环境模型，一般来说环境模型很难获取，或者从经验中学习到的环境模型有偏差，基于模型学习到的策略部署到实际环境中会有问题，因此目前流行 model free 的方式。<br />在 model free 中强化学习训练代理的方法有策略优化和 Q learning，其中策略优化每次在更新时使用的数据是根据最新的策略收集的数据，策略优化通常是是学习值函数。<br />Q-learning 通常是学习动作值函数，使用基于贝尔曼方程的目标函数，在优化时使用的数据是训练期间获得的数据，因此不依赖于最新的策略。<br />策略优化稳定可靠，并且可以直接优化想要优化的目标。而 Q learning 是通过训练贝尔曼方程来间接优化策略，不太稳定，但是样本的使用效率非常高。<br />还有就是介于这两种方法之间的算法，能够平衡两者的优劣，如 SAC 使用随机策略、熵正则化等。
<a name="NWL9p"></a>
### 策略优化

- 策略优化中的损失函数是在固定数据分布上定义的，该数据分布与要优化的参数无关；
- 损失函数通常是评估我们关心的性能指标，在机器学习中如果损失函数下降，就意味着策略的效果很好，但是在策略梯度中，只有平均的回报才意味着策略的表现是否良好，损失函数不一定。

轨迹的概率：![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256565493-b9dd0e37-6a77-4e26-b736-0b6840fb8995.png#averageHue=%23f5f5f5&clientId=u7a71cfcb-0310-4&from=paste&height=84&id=u9bc543e6&originHeight=84&originWidth=376&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4242&status=done&style=none&taskId=u507a514b-dbaa-4593-b0b0-0f0d813a87d&title=&width=376)<br />对数求导技巧：![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256594038-782e5134-f980-4090-80da-ba9c3625ed87.png#averageHue=%23f3f3f3&clientId=u7a71cfcb-0310-4&from=paste&height=60&id=uaf2053c5&originHeight=60&originWidth=293&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2983&status=done&style=none&taskId=u9ad9bb00-2edf-4e5f-aa95-d8af7e44e43&title=&width=293)<br />轨迹的对数概率：![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256620966-c4b598c5-7d0d-4605-9506-0d4c1ce2d105.png#averageHue=%23f5f5f5&clientId=u7a71cfcb-0310-4&from=paste&height=87&id=u98d27c65&originHeight=87&originWidth=534&originalType=binary&ratio=1&rotation=0&showTitle=false&size=6307&status=done&style=none&taskId=u38b5ee50-4ed3-4c60-be87-362b2010e88&title=&width=534)<br />环境函数的梯度，因为环境和策略的概率分布参数无关，所以求导为 0：<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256692852-d2a7cfff-bcaa-48fe-be0c-3c8d7b8f7925.png#averageHue=%23f6f6f6&clientId=u411f944b-2458-4&from=paste&height=134&id=u8c885a2c&originHeight=134&originWidth=643&originalType=binary&ratio=1&rotation=0&showTitle=false&size=11063&status=done&style=none&taskId=ufcd6877a-953b-4211-8a9c-e2f8fc89cd8&title=&width=643)<br />所以策略梯度可以写成：<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1720256731740-37b32b17-366b-49d5-b7cb-3606953f8f02.svg#clientId=u411f944b-2458-4&from=paste&id=u3d930a5f&originHeight=267&originWidth=597&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u1a241175-4a40-4fdc-8d71-b00ee8820d5&title=)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256780165-275169b8-865a-4b1b-903c-d56f2987ed7b.png#averageHue=%23f5f4f2&clientId=u411f944b-2458-4&from=paste&height=186&id=uadb18117&originHeight=186&originWidth=715&originalType=binary&ratio=1&rotation=0&showTitle=false&size=36786&status=done&style=none&taskId=uab0d5253-f9e1-46e7-84c3-53daa96a9a7&title=&width=715)<br />最简单的策略梯度的 pythoch 实现：[spinningup/spinup/examples/pytorch/pg_math/1_simple_pg.py at master · openai/spinningup](https://github.com/openai/spinningup/blob/master/spinup/examples/pytorch/pg_math/1_simple_pg.py)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256906508-b1d0fdae-0f06-49f4-93ad-4da27e3bf1e0.png#averageHue=%23f8f7f6&clientId=u411f944b-2458-4&from=paste&height=122&id=ubb3eca67&originHeight=122&originWidth=600&originalType=binary&ratio=1&rotation=0&showTitle=false&size=15021&status=done&style=none&taskId=u2a334f40-6b6d-41a4-b5ac-045b3a47315&title=&width=600)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256950801-7101b5b9-813a-487f-9b3b-66a2ee7801d8.png#averageHue=%23f7f6f4&clientId=u411f944b-2458-4&from=paste&height=192&id=ud89ae5ac&originHeight=192&originWidth=711&originalType=binary&ratio=1&rotation=0&showTitle=false&size=33766&status=done&style=none&taskId=u4bcab33f-ed75-49df-87dd-7f0f0730a0b&title=&width=711)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256968623-579f2108-f7da-400a-a613-eeb269247fe2.png#averageHue=%23f6f5f4&clientId=u411f944b-2458-4&from=paste&height=109&id=u347c3a9c&originHeight=109&originWidth=509&originalType=binary&ratio=1&rotation=0&showTitle=false&size=13786&status=done&style=none&taskId=uf0f30c4a-3580-4a62-a8c6-0855be8c52f&title=&width=509)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720256989953-692215ec-f961-439c-9e56-3549f99e52f0.png#averageHue=%23f6f5f4&clientId=u411f944b-2458-4&from=paste&height=159&id=u3af4bdd1&originHeight=159&originWidth=640&originalType=binary&ratio=1&rotation=0&showTitle=false&size=22233&status=done&style=none&taskId=u3807521c-4136-410d-ae21-bf5dd412c4b&title=&width=640)<br />最常见的基线函数是价值函数，表示智能体从该状态开始获得的平均回报，可以减少策略梯度样本的估计方差，导致更稳定的策略学习，保持了梯度估计的无偏性。并且如果智能体在某个状态下获得了较高的回报，但是这个回报正好是该状态下的预期回报，那么这一个状态对梯度的贡献相比于之前不使用价值函数来说会减少。<br />对于策略梯度来说，**策略梯度**具有以下的一般形式：策略梯度更新公式<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257454162-72367211-12b3-4c12-9521-f5b49f5f5fd8.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=56&id=u2c6c0c31&originHeight=56&originWidth=321&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4805&status=done&style=none&taskId=uc7e98452-602a-4b70-a978-df37c5de047&title=&width=321)其中最后的![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257471324-e40d1678-1d39-445d-8aec-a8ec19f6afd8.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=15&id=uad9e9a53&originHeight=15&originWidth=18&originalType=binary&ratio=1&rotation=0&showTitle=false&size=357&status=done&style=none&taskId=u7e175a33-a2d9-4643-8e16-cd38a73c318&title=&width=18)可以是以下任意一个函数：![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257487073-8435de42-bc21-4e77-95c1-08284004c9a4.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=19&id=ud115b831&originHeight=19&originWidth=86&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1031&status=done&style=none&taskId=ue280cca3-9771-40d6-88a0-df7336fb877&title=&width=86)![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257492408-bd86c29f-19e6-4278-bdff-2e24fe8ad32b.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=54&id=XLnLv&originHeight=54&originWidth=193&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2601&status=done&style=none&taskId=u1b594d77-875a-49ec-8493-2bccf39435a&title=&width=193)![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257497058-3f4092f1-ea95-44ea-be42-f2ac7cc901f7.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=54&id=ucd3aaa68&originHeight=54&originWidth=252&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3224&status=done&style=none&taskId=uc65e7c56-8c1a-4a8d-af0a-e1421b11553&title=&width=252)。<br />在策略动作价值函数中，![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257534293-3133ed47-7c14-4ecb-a5c6-d11d4da2233e.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=15&id=u088e3207&originHeight=15&originWidth=18&originalType=binary&ratio=1&rotation=0&showTitle=false&size=357&status=done&style=none&taskId=uf1d439f6-2d9c-4fb5-b59f-de6362e9030&title=&width=18)可以选择动作价值函数或者优势函数。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257699804-be066d61-6ad8-47e2-badc-075cfc85b746.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=19&id=u06fffd3f&originHeight=19&originWidth=123&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1514&status=done&style=none&taskId=ufaec02e3-2480-4588-b22b-1c48930b7e7&title=&width=123)![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1720257704816-5667eb25-bd5b-4c95-9fb1-834e09d89935.png#averageHue=%23000000&clientId=u411f944b-2458-4&from=paste&height=19&id=u7d7247e8&originHeight=19&originWidth=122&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1445&status=done&style=none&taskId=u897ac4ee-5f58-466e-a8d9-2283d6613e2&title=&width=122)<br />[[1506.02438] High-Dimensional Continuous Control Using Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438)论文详细描述了广泛使用的策略优化算法中近似优势函数的方法。
<a name="cJISq"></a>
### PPO
基础知识：<br />动作值函数![](https://cdn.nlark.com/yuque/__latex/2251ac180583f82c3a1f28c20d677d8c.svg#card=math&code=Q%28s%2Ca%29&id=dmjFb)，值函数![](https://cdn.nlark.com/yuque/__latex/283b1b0d0929bc6fe1f092901d366e1a.svg#card=math&code=V%28s%29&id=aUlwm)<br />即使两个分布的期望相同，但是随机变量的分布也不一定一样，如下式所示：<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723089309212-01957b3b-5ffc-4800-9560-b5a5b85e5306.png#averageHue=%23f1cb83&clientId=ue3fc70d4-89ac-4&from=paste&height=84&id=u42400015&originHeight=84&originWidth=223&originalType=binary&ratio=1&rotation=0&showTitle=false&size=8096&status=done&style=none&taskId=ua0e6d4a2-6d74-435f-b775-1df8e296ab9&title=&width=223)<br />PPO 中求导常用的公式：<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723089349459-f72932ca-4965-481e-be64-ec744f427660.png#averageHue=%23799bbc&clientId=ue3fc70d4-89ac-4&from=paste&height=41&id=u354bf52b&originHeight=41&originWidth=219&originalType=binary&ratio=1&rotation=0&showTitle=false&size=5110&status=done&style=none&taskId=ub748f956-d771-45e3-bf97-c832fdf0e96&title=&width=219)

---

PPO 是策略梯度更新得一种算法，所以解决得问题是策略梯度更新中出现的问题，策略梯度更新的公式如[3策略优化](#NWL9p)中描述的一样，具有一个一般性的公式，在 PPO 中主要是将![](https://cdn.nlark.com/yuque/__latex/212d2f473ab5a2a1d1d5efc36fd92023.svg#card=math&code=%5CPhi_t&id=fO8JX)设计为优势函数，其中优势函数具体是描述当前选择这个动作的相对好坏，是将当前动作值函数减去当前状态平均的值函数。<br />之前的![](https://cdn.nlark.com/yuque/__latex/212d2f473ab5a2a1d1d5efc36fd92023.svg#card=math&code=%5CPhi_t&id=wbZfc)是设为奖励函数，只不过这里的奖励函数是一个 episode 交互完成之后的奖励函数之和，而不是每一步操作对应的奖励，所以就会导致即使某个 action 是不对的，但是整个 episode 中有的 action 是正确的，最后的奖励函数仍然是对的，所以为了避免这种情况，我们不应该让之前的行为影响现在的 action，所以奖励函数变为了 reward to go，即奖励变为了从当前的 action 交互之后的所有奖励之和，之前的奖励不会累加到当前的 action 奖励上面，这一点在 spinning up 中的第三点[https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html#don-t-let-the-past-distract-you](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html#don-t-let-the-past-distract-you)中有官方的阐述。并且为了使奖励函数更关注当前的 action，还在奖励函数中加入了权重因子![](https://cdn.nlark.com/yuque/__latex/6818f55fc4bda4345791ed3fd47fab36.svg#card=math&code=%5Cgamma%3C1&id=b7oBP)，这样 action 乘的奖励函数将会更加关注当前动作产生的影响，很多步之后的动作产生的影响对当前的 action 应该比较小。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723089055058-9f550adf-8134-491e-88e5-8a83e6960e28.png#averageHue=%23faf9f8&clientId=ue3fc70d4-89ac-4&from=paste&height=62&id=u636dd046&originHeight=62&originWidth=790&originalType=binary&ratio=1&rotation=0&showTitle=false&size=7444&status=done&style=none&taskId=ueabd8c2f-d6e1-4ebf-b07e-054f4bc6fee&title=&width=790)<br />即使变为 reward to go 之后仍然存在一个问题，就是奖励都是正值，这就导致了如果由于某些原因没有采样到一个动作，那么这个动作的概率就一定会降低，因为奖励都是正值，但是那个没有采样到的动作不一样是不好的，所以为了解决这个问题将![](https://cdn.nlark.com/yuque/__latex/212d2f473ab5a2a1d1d5efc36fd92023.svg#card=math&code=%5CPhi_t&id=ObInd)中加入了基线函数，这个基线函数可以随便取，而在优势函数中，基线函数是当前状态的平均奖励。<br />因此 PPO 中策略梯度更新的公式为：<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723087604762-f1b48136-07b1-48d7-81a7-a843f11705ef.png#averageHue=%23f9f7f6&clientId=ue3fc70d4-89ac-4&from=paste&height=87&id=u455ae428&originHeight=87&originWidth=379&originalType=binary&ratio=1&rotation=0&showTitle=false&size=5943&status=done&style=none&taskId=u839f0334-56fe-4c42-9781-bee4197f6c4&title=&width=379)<br />PPO 原本是在线的，即训练的策略和与环境交互的策略是一个策略，但是这种方式训练的效率很慢，时间全用在和环境交互上面了，同时会浪费大量的数据。因此就提出了**重要性采样**：即与环境交互的是一个策略，训练的是另一个策略，这两个策略的分布是不一样的，为了能够训练出好的控制策略，而不是与环境交互的策略，在原先的基础之上乘了个权重，圈起来的部分就是，这样就可以从原先的 p 分布中采样变为从任意的 q 分布中采样来训练策略。<br />![](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723087916521-ae676031-d94f-48a1-9a72-c0701c208e42.png#averageHue=%23f1f1f1&clientId=ue3fc70d4-89ac-4&from=paste&id=u5b882f8a&originHeight=90&originWidth=897&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uf6728344-3cf7-4c6e-b300-80d6d319cc5&title=)<br />由下图可以看出，这两个分布是不一样的，但是只要采样的数量比较多，通过这个权重系数还是可以近似为原先 p 的分布。这样 PPO 就从在线策略变为了离线策略，即 **off-policy**.<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723088027621-640c7461-8548-4a43-b0d6-283a4cd55b78.png#averageHue=%23f3fbf7&clientId=ue3fc70d4-89ac-4&from=paste&id=u54e109f2&originHeight=3490&originWidth=5977&originalType=url&ratio=1&rotation=0&showTitle=false&size=3155019&status=done&style=none&taskId=u737445fd-7a00-449c-bb5b-95a1a3b9147&title=)<br />即使 p 分布和 q 分布可以不一致，但是这两个分布不可以差的很多，所以为了限制这两个分布的差异程度，提出了 TRPO，其中 TRPO 是将这两个分布的 **KL 散度**作为硬约束加到到目标函数中，如下图所示：KL 散度是作为约束条件在目标函数之外的。这很难去求解。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723088296388-8d579c86-c908-4593-9fff-c6ffa84b7eff.png#averageHue=%23f9f7f6&clientId=ue3fc70d4-89ac-4&from=paste&height=152&id=hQEzF&originHeight=152&originWidth=614&originalType=binary&ratio=1&rotation=0&showTitle=false&size=18073&status=done&style=none&taskId=uc4214f8f-93ff-4108-b6da-ba9de592cf8&title=&width=614)<br />所以 PPO 在 TRPO 的基础之上，将 KL 散度作为软约束加到了目标函数之内，如下图所示，并且 KL 散度的权重![](https://cdn.nlark.com/yuque/__latex/6100158802e722a88c15efc101fc275b.svg#card=math&code=%5Cbeta&id=iUvpi)可以跟据计算的效果进行更新，即如果优化之后这两个分布差距很小，那么就减小权重系数，提供更多的探索性，反之如果这两个分布差异很大，那么就增大这个权重系数。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723088397841-e9e61737-74f8-4b8d-aa67-9ec4e4cfb9cb.png#averageHue=%23f9f8f7&clientId=ue3fc70d4-89ac-4&from=paste&height=109&id=ubd1ed6e5&originHeight=109&originWidth=781&originalType=binary&ratio=1&rotation=0&showTitle=false&size=15079&status=done&style=none&taskId=uf8d4faa4-df4f-4931-8185-b8856d72d8c&title=&width=781)<br />但是 PPO 还有一个更方便的变体，这也是 OpenAI 官方使用的 PPO，就是不需要计算 KL 散度，因为计算 KL 散度实际上也很麻烦，需要将通过目标函数求出的 p 分布和原先的 q 分布进行采样，然后才能计算 KL 散度。不需要 KL 散度之后为了限制策略更新的幅度，加入了**剪裁函数**，如下图所示，即<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723088726085-a31cf3ff-4022-4027-8b0c-ed6f04d77437.png#averageHue=%23fbf9f8&clientId=ue3fc70d4-89ac-4&from=paste&height=101&id=ucb70fd3c&originHeight=101&originWidth=780&originalType=binary&ratio=1&rotation=0&showTitle=false&size=9218&status=done&style=none&taskId=ue40d271b-69f4-47e2-b3ba-72a3931a287&title=&width=780)<br />即当优势函数大于 0 的时候，为了限制 p 分布和 q 分布之间太接近，设计了上限；当优势函数小于 0 的时候，为了限制 p 分布和 q 分布之间差异过大，设计了下限，其中![](https://cdn.nlark.com/yuque/__latex/c57c5f0e31d8960d9406bb149fced9e0.svg#card=math&code=%5Cvarepsilon&id=HJ1qN)一般为 0.2。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1723088789433-f1e9a028-ef33-4dcc-a6c1-b6c58244eb5b.png#averageHue=%23f8f5f5&clientId=ue3fc70d4-89ac-4&from=paste&id=ud6ccd5e8&originHeight=407&originWidth=1171&originalType=url&ratio=1&rotation=0&showTitle=false&size=123546&status=done&style=none&taskId=u6658e252-01cf-4e1c-a974-3d6465c2b2f&title=)
<a name="hIhtt"></a>
# 强化学习的网络架构
<a name="qmTvr"></a>
## 跟李沐动手学深度学习
<a name="eDZ1J"></a>
### 符号
不同的 X 代表不同的含义，看清楚！<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719241657456-718a5e51-a09f-4183-a1fb-7467f1bdc58c.png#averageHue=%23262525&clientId=ue83b6c8d-b443-4&from=paste&height=269&id=u6ae62c43&originHeight=269&originWidth=346&originalType=binary&ratio=1&rotation=0&showTitle=false&size=16925&status=done&style=none&taskId=u0deaa2ae-1dc8-41df-a82e-33667c6d3f9&title=&width=346)![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719241669809-86aaf0f3-36b3-41ec-8ab6-49f1910895f5.png#averageHue=%23292827&clientId=ue83b6c8d-b443-4&from=paste&height=300&id=uf6e84036&originHeight=300&originWidth=440&originalType=binary&ratio=1&rotation=0&showTitle=false&size=33076&status=done&style=none&taskId=ud81412af-dca6-4d48-803f-d7c47a02073&title=&width=440)<br />指示函数：它通常用来表示一个集合或区域在某个点处的存在性或特征，比如 x 属于集合 A，则值为 1，否则值为 0。指示函数一般是一个离散的函数，它的取值只能是 0 或 1。在**实践**中，为了方便计算和优化，指示函数通常会被近似成一个连续函数，例如 sigmoid 函数（神经网络最后一层）或高斯函数等。此外，指示函数还可以被扩展到多维空间或更一般的情况下，例如对于一个区域而言，它的指示函数可以表示为一个布尔函数或特征函数。<br />连结：目前的理解是将两个数或者连接起来，后续遇到具体情况再更正。<br />集合的基数：在数学集合论中，基数或势，即集合中包含的元素的“个数”（参见势的比较），是日常交流中基数的概念在数学上的精确化（并使之不再受限于有限情形）。有限集合的基数，其意义与日常用语中的“基数”相同，例如{a,b,c}的基数是3。无限集合的基数，其意义在于比较两个集的大小，例如整数集和有理数集的基数相同；整数集的基数比实数集的小。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719241681587-fc868e49-a839-4c80-9dca-3b99bc76d1ee.png#averageHue=%23292827&clientId=ue83b6c8d-b443-4&from=paste&height=500&id=ua65d5f8d&originHeight=500&originWidth=302&originalType=binary&ratio=1&rotation=0&showTitle=false&size=35567&status=done&style=none&taskId=u86132ddb-dbbf-4321-ba22-52d04614138&title=&width=302)<br />![](https://cdn.nlark.com/yuque/__latex/65966b512f118fcc00b8c60ae86b2de1.svg#card=math&code=%5Cfrac%7Bdy%7D%7Bdx%7D&id=Nm8bA)是确定性的导数，![](https://cdn.nlark.com/yuque/__latex/c98403508ed4f41213e396ea80b4523e.svg#card=math&code=%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20x%7D&id=Rbe2p)是针对某一个变量的偏导数，![](https://cdn.nlark.com/yuque/__latex/27b721d01b9148116a9d33733ec320b8.svg#card=math&code=%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20y&id=erU4f)是 y 关于 x 的梯度，看清上下标，下标是对那个变量求梯度。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719241692797-adb9c07f-dd63-4745-88e6-5e262df76cd9.png#averageHue=%23292827&clientId=ue83b6c8d-b443-4&from=paste&height=224&id=u8d40f307&originHeight=224&originWidth=394&originalType=binary&ratio=1&rotation=0&showTitle=false&size=25419&status=done&style=none&taskId=u2833ee52-09f9-4151-8dd8-894a8ac7d04&title=&width=394)<br />![](https://cdn.nlark.com/yuque/__latex/372f84f135fa4e6a05fbb46968bf1b97.svg#card=math&code=P%28X%20%5Cmid%20Y%29&id=DmSaG)是 X 在 Y 的条件下的概率。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719241708825-fabf10cf-3f8c-422e-9cd5-8c6eefddfba8.png#averageHue=%232a2929&clientId=ue83b6c8d-b443-4&from=paste&height=450&id=u5f025f36&originHeight=450&originWidth=549&originalType=binary&ratio=1&rotation=0&showTitle=false&size=70830&status=done&style=none&taskId=u97818e7a-6049-456e-9a55-e817cb53e73&title=&width=549)<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719241717410-1dbb97f7-ad8b-4347-b691-7d7ee0074814.png#averageHue=%23292521&clientId=ue83b6c8d-b443-4&from=paste&height=91&id=ub4a17deb&originHeight=91&originWidth=205&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4494&status=done&style=none&taskId=ucdea1483-f282-49f0-a1cc-a4b120a67f9&title=&width=205)
<a name="fRoPa"></a>
### 引言
人们常用的计算机程序几乎都是软件开发人员从零编写的。 比如，现在开发人员要编写一个程序来管理网上商城。根据业务逻辑设计自动化系统，驱动正常运行的产品和系统，是一个人类认知上的非凡壮举。<br />但是要编写一个应用程序，向用户推荐他们可能喜欢，但在自然浏览过程中不太可能遇到的产品。在这些情况下，即使是顶级程序员也无法提出完美的解决方案。_**机器学习**_（machine learning，ML）是一类强大的可以从经验中学习的技术。 通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。 相反，对于刚刚所说的电子商务平台，如果它一直执行相同的业务逻辑，无论积累多少经验，都不会自动提高，除非开发人员认识到问题并更新软件
<a name="o7UsC"></a>
#### 日常中的机器学习
现在，假如需要我们编写程序来响应一个“唤醒词”（比如“Alexa”“小爱同学”和“Hey Siri”）。 我们试着用一台计算机和一个代码编辑器编写代码，如 图1.1.1中所示。 问题看似很难解决：麦克风每秒钟将收集大约44000个样本，每个样本都是声波振幅的测量值。而该测量值与唤醒词难以直接关联。那又该如何编写程序，令其输入麦克风采集到的原始音频片段,输出是否（表示该片段是否包含唤醒词）的可靠预测呢？我们对编写这个程序毫无头绪，这就是需要机器学习的原因。<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1719243013957-9ca0c7b7-f0e9-4bdd-9f65-185d773c332a.svg#clientId=ue83b6c8d-b443-4&from=paste&id=u1b0575e5&originHeight=65&originWidth=385&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uf1029b49-1fc2-4b1f-b79e-fe8d644aeed&title=)<br />图1.1.1 识别唤醒词<br />即使我们不知道如何编写计算机程序来识别“Alexa”这个词，大脑自己也能够识别它。 有了这一能力，我们就可以收集一个包含大量音频样本的**数据集**（dataset），并对包含和不包含唤醒词的样本进行标记。 利用机器学习算法，我们不需要设计一个“明确地”识别唤醒词的系统。 相反，我们只需要定义一个灵活的程序算法，其输出由许多**参数**（parameter）决定，然后使用数据集来确定当下的“最佳参数集”，这些参数通过某种性能度量方式来达到完成任务的最佳性能。<br />参数可以被看作旋钮，旋钮的转动可以调整程序的行为。 任一调整参数后的程序被称为**模型**（model）。 通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。 使用数据集来选择参数的元程序被称为**学习算法**（learning algorithm）。<br />在开始用机器学习算法解决问题之前，我们必须精确地定义问题，确定**输入 **（input）和**输出**（output）的性质，并选择合适的模型族。<br />在机器学习中，**学习**（learning）是一个训练模型的过程。 通过这个过程，我们可以发现正确的参数集，从而使模型强制执行所需的行为。 换句话说，我们用数据**训练**（train）模型。 如图1.1.2所示，训练过程通常包含如下步骤：<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1719243592983-8993ec79-51dd-4085-9b94-3e9203a4ddfb.svg#clientId=ue83b6c8d-b443-4&from=paste&id=u2bac8d25&originHeight=127&originWidth=396&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u0f184ce4-4abd-4f90-bbeb-8c2d828c7e5&title=)<br />图1.1.2 一个典型的训练过程
<a name="bbuIg"></a>
#### 机器学习中的关键组件

1. 可以用来学习的_**数据**_（data）；
2. 如何转换数据的_**模型**_（model）；
3. 一个_**目标函数**_（objective function），用来量化模型的有效性；
4. 调整模型参数以优化目标函数的_**算法**_（algorithm）。
<a name="FU9JN"></a>
##### 数据
每个数据集由一个个_**样本**_（example, sample）组成，大多时候，它们遵循**独立同分布**(independently and identically distributed, i.i.d.)。 样本有时也叫做_**数据点**_（data point）或者_**数据实例**_（data instance），通常每个样本由一组称为_**特征**_（features，或_**协变量**_（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为_**标签**_（label，或_目标_（target））。<br />当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的_**维数**_（dimensionality）。<br /> 与传统机器学习方法相比，深度学习的一个主要优势是可以处理**不同长度**的数据。<br /> 数据集的由小变大为现代深度学习的成功奠定基础。 在没有大数据集的情况下，许多令人兴奋的深度学习模型黯然失色。 就算一些深度学习模型在小数据集上能够工作，但其效能并不比传统方法高。<br />数据很重要！当数据不具有充分代表性，甚至包含了一些社会偏见时，模型就很有可能有偏见。
<a name="pyibg"></a>
##### 模型
大多数机器学习会涉及到数据的转换。 比如一个“摄取照片并预测笑脸”的系统。再比如通过摄取到的一组传感器读数预测读数的正常与异常程度。 虽然简单的模型能够解决如上简单的问题，但本书中关注的问题超出了经典方法的极限。 深度学习与经典方法的区别主要在于：深度学习关注的是功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为_**深度学习**_（deep learning）。
<a name="XTITQ"></a>
##### 目标函数
在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为_**目标函数**_（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为_**损失函数**_（loss function，或cost function）。<br />当任务在试图预测数值时，最常见的损失函数是_**平方误差**_（squared error），即预测值与实际值之差的平方。 当试图解决分类问题时，最常见的目标函数是**最小化错误率**，即预测与实际情况不符的样本比例。 有些目标函数（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其他复杂性难以直接优化。 在这些情况下，通常会优化_替代目标_。<br /> 在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为_**训练数据集**_（training dataset，或称为_训练集_（training set））。 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为_**测试数据集**_（test dataset，或称为_测试集_（test set））。<br />综上所述，可用数据集通常可以分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。 
<a name="cEX6y"></a>
##### 优化算法
当我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。 深度学习中，大多流行的优化算法通常基于一种基本方法**–**_**梯度下降**_（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。
<a name="hg5yO"></a>
#### 各种机器学习问题
<a name="gUlql"></a>
##### 监督学习
_监督学习_（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个_**样本**_（example）。 有时，即使标签是未知的，样本也可以指代输入特征。 我们的目标是生成一个模型，能够将任何输入特征**映射**到标签（即预测）。<br />监督学习一般分为三个步骤：

1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，这些样本可能需要被人工标记（例如，图像分类）。这些输入和相应的标签一起构成了训练数据集；
2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。

![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1719844684922-9e400e3a-fdb6-4e23-9a2b-d8ea8925be61.svg#clientId=u39499c20-3b74-4&from=paste&id=u21f55c83&originHeight=124&originWidth=407&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ufe7c1d7a-b1b3-4f69-8ba6-32f85d24f1a&title=)<br />监督学习
<a name="lhtCu"></a>
###### 回归
回归是利用已有的特征向量去预测标签，回归的目标是生成一个模型或者函数，使它的预测非常接近实际标签值，一般采用平方误差损失函数最小化。比如说用最小二乘法拟合一条曲线就是回归。
<a name="ZTVqA"></a>
###### 分类
_分类_问题希望模型能够预测样本属于哪个_类别_（category，正式称为_类_（class））。 最简单的分类问题是只有两类，这被称之为_二项分类_（binomial classification）。 例如，数据集可能由动物图像组成，标签可能是猫和狗两类。 回归是训练一个回归函数来输出一个数值； 分类是训练一个分类器来输出预测的类别。_其实将输出的数值进行认为划分也可以变成分类，比如输入一个的概率是 0.9，我就认为是这一类。_<br />当有两个以上的类别时，我们把这个问题称为_多项分类_（multiclass classification）问题。 常见的例子包括手写字符识别 0-9 和 26 个字母。 与解决回归问题不同，分类问题的常见损失函数被称为_交叉熵_（cross-entropy），本书 [3.4节](https://zh.d2l.ai/chapter_linear-networks/softmax-regression.html#sec-softmax) 将详细阐述。
<a name="GOv4N"></a>
###### 标记问题
学习预测不相互排斥的类别的问题称为_多标签分类_（multi-label classification）。比如下面这个图片里面有各种动物，使用多项分类输出这是什么动物明显不符合日常认知，这时就需要输出这里面有哪些标签或者类别，这些类别之间是不相互排斥的，不能说里面有坤就不能有猫了。<br />![](https://cdn.nlark.com/yuque/0/2024/png/39264174/1719845367675-439b9393-e498-408c-8b6b-85af02920255.png#averageHue=%234c5150&clientId=u39499c20-3b74-4&from=paste&id=u6054d5fa&originHeight=843&originWidth=620&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ufde7959b-bed6-444b-8042-5839a5dd147&title=)
<a name="qA3oS"></a>
###### 搜索
我们在搜索引擎输入关键词进行搜索时，不仅需要找到相关的内容，还需要对内容进行排序，把最相关的放到最上面，这就是**搜索**排序。一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。[PageRank](https://en.wikipedia.org/wiki/PageRank)，谷歌搜索引擎背后最初的秘密武器就是这种评分系统的早期例子，但它的奇特之处在于它不依赖于实际的查询。 
<a name="NtF1c"></a>
###### 推荐
推荐时将用户和物品相关联起来，找到最适合这个用户的产品，给用户进行个性化推荐，当然可以按照其他人检索得分最高的产品推给一个新用户，但是现在的推荐算法会考虑到详细的用户行为和项目特征。<br />推荐带来的一个灾难性问题是用的多的东西用的越多，但是这个产品并不一定是最好的，可能对于某个用户来说。
<a name="SvRbd"></a>
###### 序列学习
以上大多数问题都具有固定大小的输入和产生固定大小的输出。 但是对于翻译来说，输入和输出的大小不是固定的，甚至目前的输入还要和之前的输入有关联，输入之间不是相互独立的，比如在翻译时需要考虑上下文的含义。还有一个例子就是语音识别，输入是一段音频，输出是文字，音频采样通常是 8k hz 或者 16k hz，这里输入和输出就是数千个样本对应一个输出，反过来还有文字生成语音等等。
<a name="eRKN5"></a>
##### 无监督学习
监督学习通常是输入的样本中包含特征和对应的标签值，但是无监督学习是样本中没有标签。<br />无监督学习主要解决下面几个问题：

- _聚类_（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？
- _主成分分析_（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。另一个例子：在欧几里得空间中是否存在一种（任意结构的）对象的表示，使其符号属性能够很好地匹配?这可以用来描述实体及其关系，例如“罗马” − “意大利” + “法国” = “巴黎”。
- _因果关系_（causality）和_概率图模型_（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？
- _**生成对抗性网络**_（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。
<a name="p9UTx"></a>
##### 与环境交互
不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为_离线学习_（offline learning）。对于监督学习，从环境中收集数据的过程类似于下图。<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1719846511298-62844f03-7890-4d5f-9153-509e5078d205.svg#clientId=u39499c20-3b74-4&from=paste&id=ubfcdb670&originHeight=183&originWidth=403&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u6c16b9c7-12bd-45a4-a3e5-dbfbcabbb7b&title=)<br />监督学习解决的问题相当有限，因为只有当时离线的数据，除非离线的数据包含所有情况，实际上不可能，数据量太庞大了。 这时我们可能会期望人工智能不仅能够做出预测，而且能够与真实环境互动。 与预测不同，“与真实环境互动”实际上会影响环境。这里的人工智能是“智能代理”，而不仅是“预测模型”。 因此，我们必须考虑到它的行为可能会影响未来的观察结果。
<a name="hKCU7"></a>
##### 强化学习
_**深度强化学习**_（deep reinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。 突破性的**深度**_**Q网络**_（Q-network）在雅达利游戏中仅使用视觉输入就击败了人类， 以及 AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1719846723482-822849a1-dd0f-41c6-ba64-35a1ba739771.svg#clientId=u39499c20-3b74-4&from=paste&id=u8531bb5f&originHeight=172&originWidth=383&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ubcd0af7e-af8e-4011-8e53-ceeade4b80e&title=)<br />强化学习框架的通用性十分强大。 例如，我们可以将任何监督学习问题转化为强化学习问题。 假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。 然后，我们可以创建一个环境，该环境给予智能体的奖励。 这个奖励与原始监督学习问题的损失函数是一致的。<br />当然，强化学习还可以解决许多监督学习无法解决的问题。 例如，在监督学习中，我们总是希望输入与正确的标签相关联。 但在强化学习中，我们并不假设环境告诉智能体每个观测的最优动作。 一般来说，智能体只是得到一些奖励。 此外，环境甚至可能不会告诉是哪些行为导致了奖励。所以智能体需要找到其中的内在联系。<br />最后，在任何时间点上，强化学习智能体可能知道一个好的策略，但可能有许多更好的策略从未尝试过的。 强化学习智能体必须不断地做出选择：是应该利用当前最好的策略，还是探索新的策略空间（放弃一些短期回报来换取知识）。<br />当环境可被完全观察到时，强化学习问题被称为_**马尔可夫决策过程**_（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为_**上下文赌博机**_（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的_**多臂赌博机**_（multi-armed bandit problem）。
<a name="plhD9"></a>
#### 特点
机器学习可以使用数据来学习输入和输出之间的转换，例如在语音识别中将音频转换为文本。 在这样做时，通常需要以适合算法的方式表示数据，以便将这种表示转换为输出。 深度学习是“深度”的，模型学习了许多“层”的转换，每一层提供一个层次的表示。 例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。 由于_表示学习_（representation learning）目的是寻找表示本身，因此深度学习可以称为“多级表示学习”。<br />从原始音频信号中学习，图像的原始像素值，或者任意长度的句子与外语中的对应句子之间的映射，都是深度学习优于传统机器学习方法的问题。 事实证明，这些多层模型能够以以前的工具所不能的方式处理低级的感知数据。 <br />深度学习方法中最显著的共同点是使用端到端训练。 也就是说，与其基于单独调整的组件组装系统，不如构建系统，然后联合调整它们的性能。 例如，在过去的计算机视觉中，科学家们习惯于将特征工程的过程与建立机器学习模型的过程分开。 Canny边缘检测器 ([Canny, 1987](https://zh.d2l.ai/chapter_references/zreferences.html#id20)) 和SIFT特征提取器 ([Lowe, 2004](https://zh.d2l.ai/chapter_references/zreferences.html#id102)) 作为将图像映射到特征向量的算法，在过去的十年里占据了至高无上的地位。 在过去的日子里，将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法，将数据转换为某种适合于浅层模型的形式。 然而，与一个算法自动执行的数百万个选择相比，人类通过特征工程所能完成的事情很少。 当深度学习开始时，这些特征抽取器被**自动调整的滤波器**所取代，产生了更高的精确度。即不需要人为的设置特征工程，使用学习的方法不断进行尝试，进行更多维度更精细的尝试，最极端的例子就是暴力搜索最后的结果一定是最优的。
<a name="kenOu"></a>
#### 小结

- 机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。
- 表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。
- 深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。
- 最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（**通过GPU）算力**的突破来触发的。
- 整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。
<a name="q50tC"></a>
### 预备知识
<a name="PUgqa"></a>
#### 数据操作
n 维数组在 pytorch 和 tensorflow 中叫做张量类（tensor）,tensor 支持自动微分，并且支持 GPU 加速计算。<br />张量需要指定在 GPU 上才能加速计算，否则默认是在内存中，基于 CPU 计算。<br />torch.shape 返回张量沿每个轴的形状。<br />torch.size 返回张量中元素的总数<br />torch.reshape（x, y）可以将改变一个张量的形状，但张量的大小不会变；<br />标准运算符加减乘除、求指数等等都是对张量中的元素进行计算；<br />torch.cat（（x, y），dim=0) 可以把两个张量按照指定的轴进行连接起来。<br />**广播**机制：两个形状不一样的张量，可以通过广播机制变为同一个形状，然后在进行按元素操作计算。<br />张量可以提供数组来进行索引特定的数组，这些数组可以不连续。<br />不过要注意的是，张量必须要大小一致，即列表中的每个数组的大小是一样的，否则不能转为 tensor；<br />为了节省内存，可以将新计算的结果存储到原数组中。比如 x=x+y 这种；<br />张量变为标量可以使用.item（）但是这个只能一个元素进行转换。<br />x>y 得到是一个布尔型的张量，其中的结果由 x 和 y 中的元素进行比较得到；
```
torch.arange(20).reshape(5, 4)
```
arange 是生成一个 0-19 的 tensor 一维张量，然后 reshape 将这个一维张量变为 5*4 的张量形状。
<a name="DAKK4"></a>
#### 数据预处理
处理缺失值可以采用 fillna（x），这将读取的数据中缺失的值用 x 来填充。
<a name="tT2IG"></a>
#### 线性代数
两个张量点乘是用"*"来计算，针对每个元素进行计算，<br />可以通过求和或者求均值来降低张量指定轴的维度；<br />两个张量点积是用 dot(x, y)来计算；<br />矩阵向量积使用 torch.mv(x, y)；<br />矩阵相乘使用 torch.mm(x, y);<br />范数的性质：

1. 如果我们按常数因子![](https://cdn.nlark.com/yuque/__latex/18d25ca4f77a9bbed9812e2bb0b350a5.svg#card=math&code=%5Calpha&id=xqbnL)缩放向量的所有元素， 其范数也会按相同常数因子的_绝对值_缩放：![](https://cdn.nlark.com/yuque/__latex/5254e7fc1786b42afc64a5ef9a94c025.svg#card=math&code=f%28%5Calpha%20%5Cmathbf%7Bx%7D%29%20%3D%20%7C%5Calpha%7C%20f%28%5Cmathbf%7Bx%7D%29.&id=QsRsf)
2. 满足三角不等式：![](https://cdn.nlark.com/yuque/__latex/752c695aff9ceec80e733668167b46ba.svg#card=math&code=f%28%5Cmathbf%7Bx%7D%20%2B%20%5Cmathbf%7By%7D%29%20%5Cleq%20f%28%5Cmathbf%7Bx%7D%29%20%2B%20f%28%5Cmathbf%7By%7D%29.&id=kYZzm)
3. 范数必须是非负的：![](https://cdn.nlark.com/yuque/__latex/51ea5e525d421cabaf77475c21b506a9.svg#card=math&code=f%28%5Cmathbf%7Bx%7D%29%20%5Cgeq%200.&id=lXqEm)当且仅当向量全为 0 时，范数才是 0.

常见的二范数![](https://cdn.nlark.com/yuque/__latex/6cbe0ba6e4bf4752f798869df1da73bf.svg#card=math&code=%5C%7C%5Cmathbf%7Bx%7D%5C%7C_2&id=dKCxd)是欧几里得距离：![](https://cdn.nlark.com/yuque/__latex/c0e3337f72837db0e425285fcc4074f2.svg#card=math&code=%5C%7C%5Cmathbf%7Bx%7D%5C%7C_2%20%3D%20%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5En%20x_i%5E2%7D%2C&id=yhteq)通常情况下省略下标 2，变为![](https://cdn.nlark.com/yuque/__latex/7fcea29dc55a707c04963b69589f7763.svg#card=math&code=%5C%7C%5Cmathbf%7Bx%7D%5C%7C&id=x7Ax0)。<br />一范数![](https://cdn.nlark.com/yuque/__latex/8774782e75650651e5d3a5ded5c77e44.svg#card=math&code=L_1&id=J1Ymj)是所有元素的绝对值之和：![](https://cdn.nlark.com/yuque/__latex/73c5510b8cacaa97ede10ae77c368721.svg#card=math&code=%5C%7C%5Cmathbf%7Bx%7D%5C%7C_1%20%3D%20%5Csum_%7Bi%3D1%7D%5En%20%5Cleft%7Cx_i%20%5Cright%7C.&id=p1Oih)一范数受异常值的影响相较于二范数会比较小，因为不需要平方。<br />类似于向量的二范数，矩阵![](https://cdn.nlark.com/yuque/__latex/5df80402f7d42243460d9c8e1b937952.svg#card=math&code=%5Cmathbf%7BX%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D&id=tD1r3)的_Frobenius范数_（Frobenius norm）是矩阵元素平方和的平方根：![](https://cdn.nlark.com/yuque/__latex/76eb0979282f51c93411e94633c38e47.svg#card=math&code=%5C%7C%5Cmathbf%7BX%7D%5C%7C_F%20%3D%20%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5Em%20%5Csum_%7Bj%3D1%7D%5En%20x_%7Bij%7D%5E2%7D.&id=FOe7P)<br />**小结**：

- 标量、向量、矩阵和张量是线性代数中的基本数学对象。
- 向量泛化自标量，矩阵泛化自向量。
- 标量、向量、矩阵和张量分别具有零、一、二和任意数量的轴。
- 一个张量可以通过`sum`和`mean`沿指定的轴降低维度。
- 两个矩阵的按元素乘法（即对应元素直接相乘）被称为他们的Hadamard积。它与矩阵乘法（第一个矩阵第一行乘第二个矩阵第一列）不同。
- 在深度学习中，我们经常使用范数，如一范数、二范数和Frobenius范数。
- 我们可以对标量、向量、矩阵和张量执行各种操作。
<a name="JQVEF"></a>
#### 微积分
导数的定义：![](https://cdn.nlark.com/yuque/__latex/af1072d62df6c92bc459951678e19c42.svg#card=math&code=f%27%28x%29%20%3D%20%5Clim_%7Bh%20%5Crightarrow%200%7D%20%5Cfrac%7Bf%28x%2Bh%29%20-%20f%28x%29%7D%7Bh%7D.&id=zG9zM)<br />给定![](https://cdn.nlark.com/yuque/__latex/e636c536eaf5442066005a809249aea6.svg#card=math&code=y%3Df%28x%29&id=WzSMB)那么以下表示式是等效的:<br />![](https://cdn.nlark.com/yuque/__latex/f7a66a0685d0d6d2f9ad4e2a5ea41675.svg#card=math&code=f%27%28x%29%20%3D%20y%27%20%3D%20%5Cfrac%7Bdy%7D%7Bdx%7D%20%3D%20%5Cfrac%7Bdf%7D%7Bdx%7D%20%3D%20%5Cfrac%7Bd%7D%7Bdx%7D%20f%28x%29%20%3D%20Df%28x%29%20%3D%20D_x%20f%28x%29%2C&id=GPfmq)<br />导数有乘法法则 、加法法则、乘法法则和除法法则，其中乘法法则为：<br />![](https://cdn.nlark.com/yuque/__latex/5dd961e74898959b3d70294c3a002a47.svg#card=math&code=%5Cfrac%7Bd%7D%7Bdx%7D%20%5Bf%28x%29g%28x%29%5D%20%3D%20f%28x%29%20%5Cfrac%7Bd%7D%7Bdx%7D%20%5Bg%28x%29%5D%20%2B%20g%28x%29%20%5Cfrac%7Bd%7D%7Bdx%7D%20%5Bf%28x%29%5D%2C&id=jhnvr)<br />除法法则为：<br />![](https://cdn.nlark.com/yuque/__latex/a64075c15f0434edaf6f56805466eb00.svg#card=math&code=%5Cfrac%7Bd%7D%7Bdx%7D%20%5Cleft%5B%5Cfrac%7Bf%28x%29%7D%7Bg%28x%29%7D%5Cright%5D%20%3D%20%5Cfrac%7Bg%28x%29%20%5Cfrac%7Bd%7D%7Bdx%7D%20%5Bf%28x%29%5D%20-%20f%28x%29%20%5Cfrac%7Bd%7D%7Bdx%7D%20%5Bg%28x%29%5D%7D%7B%5Bg%28x%29%5D%5E2%7D.&id=EDHJ0)<br />假设![](https://cdn.nlark.com/yuque/__latex/0f0f2f66ced85959857b9c8a7777e885.svg#card=math&code=y%20%3D%20f%28x_1%2C%20x_2%2C%20%5Cldots%2C%20x_n%29&id=GQmte)是具有 n 个变量的函数，则关于第 i 个变量的偏导数定义：![](https://cdn.nlark.com/yuque/__latex/6bead467e91e902a894de9146f3e8ad7.svg#card=math&code=%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20x_i%7D%20%3D%20%5Clim_%7Bh%20%5Crightarrow%200%7D%20%5Cfrac%7Bf%28x_1%2C%20%5Cldots%2C%20x_%7Bi-1%7D%2C%20x_i%2Bh%2C%20x_%7Bi%2B1%7D%2C%20%5Cldots%2C%20x_n%29%20-%20f%28x_1%2C%20%5Cldots%2C%20x_i%2C%20%5Cldots%2C%20x_n%29%7D%7Bh%7D.&id=gI4Ze)<br />在计算偏导数时，可以将其他变量当做常数：<br />![](https://cdn.nlark.com/yuque/__latex/99e88dae32beded60aea62cc98baa5dd.svg#card=math&code=%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20x_i%7D%20%3D%20%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x_i%7D%20%3D%20f_%7Bx_i%7D%20%3D%20f_i%20%3D%20D_i%20f%20%3D%20D_%7Bx_i%7D%20f.&id=p1w93)<br />**梯度**：把一个多元函数对所有变量的偏导数连结起来就是这个函数的梯度（gradient）向量，假设函数的输入是一个 n 维向量：![](https://cdn.nlark.com/yuque/__latex/2b422c60615acb7744c31866d5f8077e.svg#card=math&code=%5Cmathbf%7Bx%7D%3D%5Bx_1%2Cx_2%2C%5Cldots%2Cx_n%5D%5E%5Ctop&id=ljHbA)，那么函数![](https://cdn.nlark.com/yuque/__latex/d1fed5d79d625df8f8cc788edf0f0328.svg#card=math&code=f%28%5Cmathbf%7Bx%7D%29&id=YzQdc)相对于 x 的梯度是一个包含 n 个偏导数的向量:![](https://cdn.nlark.com/yuque/__latex/86966022be2eb63e11e01921a214c1da.svg#card=math&code=%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20f%28%5Cmathbf%7Bx%7D%29%20%3D%5Cnabla%20f%28%5Cmathbf%7Bx%7D%29%3D%20%5Cbigg%5B%5Cfrac%7B%5Cpartial%20f%28%5Cmathbf%7Bx%7D%29%7D%7B%5Cpartial%20x_1%7D%2C%20%5Cfrac%7B%5Cpartial%20f%28%5Cmathbf%7Bx%7D%29%7D%7B%5Cpartial%20x_2%7D%2C%20%5Cldots%2C%20%5Cfrac%7B%5Cpartial%20f%28%5Cmathbf%7Bx%7D%29%7D%7B%5Cpartial%20x_n%7D%5Cbigg%5D%5E%5Ctop%2C&id=kXNds)<br />在微分多元函数时经常使用以下规则：

- 对于所有![](https://cdn.nlark.com/yuque/__latex/ce93bb4a23a774bc0da16df81cecf52b.svg#card=math&code=%5Cmathbf%7BA%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D&id=yZaaq)，都有![](https://cdn.nlark.com/yuque/__latex/10f0f9dd3be7340f317ee5700a78c0ff.svg#card=math&code=%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Bx%7D%20%3D%20%5Cmathbf%7BA%7D%5E%5Ctop&id=GZeq3)，因为只有对角线上的元素在求偏导数时才为 1，其他位置都是 0，因为在求偏导数时，其他变量相当于常数。Ax 的结果是一个列向量，然后依次对每一行求偏导数，对 x1 求偏导的结果是一个列向量，分别是 a11,a21,a31...这种，然后观察梯度的公式，是将求得每一个偏导数连结成一行，然后进行转置，也就是说 Ax 对每一个变量 x 求完偏导数之后，都是一个个列向量，然后连结成一个矩阵，恰巧连结的矩阵就是原矩阵 A，然后进行转置就是 A 的转置。其他同理。
- 对于所有![](https://cdn.nlark.com/yuque/__latex/6767e8a20e067bdab3b882f860ffad84.svg#card=math&code=%5Cmathbf%7BA%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20m%7D&id=CR6nZ)，都有![](https://cdn.nlark.com/yuque/__latex/91f8934b92dcb329e754274d53ea5f68.svg#card=math&code=%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cmathbf%7Bx%7D%5E%5Ctop%20%5Cmathbf%7BA%7D%20%3D%20%5Cmathbf%7BA%7D&id=HCNLB)
- 对于所有![](https://cdn.nlark.com/yuque/__latex/bd4b0a03c7a35668a9ab8058a94f1fa0.svg#card=math&code=%5Cmathbf%7BA%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20n%7D&id=Sx7J4)，都有![](https://cdn.nlark.com/yuque/__latex/3131129efbc67585259c00051504ea8f.svg#card=math&code=%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cmathbf%7Bx%7D%5E%5Ctop%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Bx%7D%20%3D%20%28%5Cmathbf%7BA%7D%20%2B%20%5Cmathbf%7BA%7D%5E%5Ctop%29%5Cmathbf%7Bx%7D&id=m0cUo)
- ![](https://cdn.nlark.com/yuque/__latex/41b8f41aaabe94a023e186631ec28f1d.svg#card=math&code=%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5C%7C%5Cmathbf%7Bx%7D%20%5C%7C%5E2%20%3D%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cmathbf%7Bx%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%20%3D%202%5Cmathbf%7Bx%7D&id=KWUVc)

**链式法则**：考虑一个更一般的场景，即函数具有任意数量的变量的情况。 假设可微分函数 y 有变量![](https://cdn.nlark.com/yuque/__latex/0a99bec2d00a035e4ba01601133bce01.svg#card=math&code=u_1%2C%20u_2%2C%20%5Cldots%2C%20u_m&id=eajll)，每个可微分的函数 ![](https://cdn.nlark.com/yuque/__latex/cd0edf8a05e48bdf774e84989c25e619.svg#card=math&code=u_i&id=ATVr2) 都有变量![](https://cdn.nlark.com/yuque/__latex/e42a368f041262444bfc3ddbaf1dd313.svg#card=math&code=x_1%2C%20x_2%2C%20%5Cldots%2C%20x_n&id=qnQ3i)，那么 y 对于 x 的导数为：<br />![](https://cdn.nlark.com/yuque/__latex/2965920a4f1ed03c95db839c6bad39e0.svg#card=math&code=%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20x_i%7D%20%3D%20%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20u_1%7D%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20x_i%7D%20%2B%20%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20u_2%7D%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20x_i%7D%20%2B%20%5Ccdots%20%2B%20%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20u_m%7D%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20x_i%7D&id=U7ZzK)<br />y 需要对所有的中间变量 u 进行求导，然后中间变量 u 再对 x 求导。<br />**小结**：

- 导数可以被解释为函数相对于其变量的瞬时变化率，它也是函数曲线的切线的斜率。
- 梯度是一个向量，其分量是多变量函数相对于其所有变量的偏导数。
- 链式法则可以用来微分复合函数。
<a name="ZKite"></a>
#### 自动微分
深度学习框架通过自动计算导数，即_自动微分_（automatic differentiation）来加快求导。 实际中，根据设计好的模型，系统会构建一个_计算图_（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，_反向传播_（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。<br />自动微分之前，需要将梯度附加到需要求梯度的变量 x 上，
```
x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)
```
y 是 x 的函数，比如 y = 2 * torch.dot(x, x)，然后对函数 y 调用反向传播函数来自动计算 y 关于 x 每个分量的梯度，然后访问 x 的梯度。
```
y.backward()
x.grad
```
对于函数 y 不是标量的时候，求导的结果可以是一个高阶的张量，只不过要保证 y 对于 x 是可微的。<br />**分离计算**：即在计算梯度的时候不计算中间变量的梯度。<br />假设`y`是作为`x`的函数计算的，而`z`则是作为`y`和`x`的函数计算的。 我们想计算`z`关于`x`的梯度，但由于某种原因，希望将`y`视为一个常数， 并且只考虑到`x`在`y`被计算后发挥的作用。<br />这里可以分离`y`来返回一个新变量`u`，该变量与`y`具有相同的值， 但丢弃计算图中如何计算`y`的任何信息。 换句话说，梯度不会向后流经`u`到`x`。 因此，下面的反向传播函数计算`z=u*x`关于`x`的偏导数，同时将`u`作为常数处理， 而不是`z=x*x*x`关于`x`的偏导数。<br />**控制流梯度计算**：当构建函数的计算图需要通过控制流（就是 if  for 等循环条件或者任意的函数）时，如果手动计算微分需要考虑各种情况，而自动微分不需要手动计算，它可以自动解析计算图中的所有控制流，提高效率。<br />**小结**：

- 深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上，然后记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。
<a name="KLcUJ"></a>
#### 概率
**贝叶斯**公式：<br />![](https://cdn.nlark.com/yuque/__latex/45760c5c608058b26eb68e3d20fdf47e.svg#card=math&code=P%28A%20%5Cmid%20B%29%20%3D%20%5Cfrac%7BP%28B%20%5Cmid%20A%29%20P%28A%29%7D%7BP%28B%29%7D.&id=lTBPS)<br />**多元变量**的贝叶斯公式：<br />P(A|B,C)=P(A,B,C)/P(B,C)<br />=P(C|A,B)*P(A,B)/P(B,C)<br />= P(C|A,B)*P(B|A)*P(A)/P(C|B)*P(B)<br />**边际化**：即不直接计算 B 的概率，而是将所有 AB 的概率进行求和，得到 B 的概率<br />![](https://cdn.nlark.com/yuque/__latex/7e8369ccb369315144ac921f6e453d62.svg#card=math&code=P%28B%29%20%3D%20%5Csum_%7BA%7D%20P%28A%2C%20B%29%2C&id=pi5mg)<br />**独立**性：![](https://cdn.nlark.com/yuque/__latex/1035fc4f6c32915e25264dae811d1b1a.svg#card=math&code=P%28A%2C%20B%29%20%3D%20P%28A%29P%28B%29&id=s6gyM)<br />**期望**：连续变量的期望为：![](https://cdn.nlark.com/yuque/__latex/aaaaea64f223eb9039f04fa6c92d1108.svg#card=math&code=E_%7Bx%20%5Csim%20P%7D%5Bf%28x%29%5D%20%3D%20%5Csum_x%20f%28x%29%20P%28x%29.&id=UCs14)<br />离散变量的期望为：![](https://cdn.nlark.com/yuque/__latex/2c554d68e9370bd58f73607526b071eb.svg#card=math&code=E%5BX%5D%20%3D%20%5Csum_%7Bx%7D%20x%20P%28X%20%3D%20x%29.&id=tmcGI)<br />**方差**：![](https://cdn.nlark.com/yuque/__latex/0aa87af2c35109cf09be2d2cfbd34fd1.svg#card=math&code=%5Cmathrm%7BVar%7D%5BX%5D%20%3D%20E%5Cleft%5B%28X%20-%20E%5BX%5D%29%5E2%5Cright%5D%20%3D%0AE%5BX%5E2%5D%20-%20E%5BX%5D%5E2.%20%20&id=J8otE)<br />因为![](https://cdn.nlark.com/yuque/__latex/94032d5ab1b4916bc718cb507a6887e2.svg#card=math&code=E%28XE%5BX%5D%29%3DE%5BX%5D%2AE%28X%29%3DE%5BX%5D%5E2&id=oGIyy)<br />**小结**：

- 我们可以从概率分布中采样。
- 我们可以使用联合分布、条件分布、Bayes定理、边缘化和独立性假设来分析多个随机变量。
<a name="YyGCI"></a>
#### 查阅文档
可以调用`dir`函数。 例如，我们可以查询随机数生成模块中的所有属性：
```
import torch

print(dir(torch.distributions))
```
有关如何使用给定函数或类的更具体说明，可以调用`help`函数。 例如，我们来查看张量`ones`函数的用法。
```
help(torch.ones)
```
<a name="lJ9Ip"></a>
### 线性神经网络
<a name="FEN6k"></a>
#### 线性回归基础知识
线性回归的的数据集称为训练数据集或者数据样本，预测的目标称为标签或者目标，预测所依据的自变量称为特征或者协变量。<br />线性回归的模型是：![](https://cdn.nlark.com/yuque/__latex/5d41eb9b218de1a9fb13540c1b422804.svg#card=math&code=%7B%5Chat%7B%5Cmathbf%7By%7D%7D%7D%20%3D%20%5Cmathbf%7BX%7D%20%5Cmathbf%7Bw%7D%20%2B%20b&id=bdjoX)，给定训练数据的特征 X 和已知标签 y，线性回归的目标是找到一组权重向量 w 和偏置 b，当给定从 X 的同分布中取样的新样本特征时，能够使预测的标签误差尽可能小。<br />_**损失函数**_（loss function）能够量化目标的_实际_值与_预测_值之间的差距。 通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。 回归问题中最常用的损失函数是平方误差函数。 <br />![](https://cdn.nlark.com/yuque/__latex/0f56fc54c478904905a454b0ff607917.svg#card=math&code=l%5E%7B%28i%29%7D%28%5Cmathbf%7Bw%7D%2C%20b%29%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%28%5Chat%7By%7D%5E%7B%28i%29%7D%20-%20y%5E%7B%28i%29%7D%5Cright%29%5E2.&id=elcxy)<br />对于无法得到解析解的损失函数，通常是使用梯度下降的方式更新参数，梯度下降是计算数据集中所有样本的损失均值关于模型参数的导数，为了加快计算速度，通常是随机抽取一小批样本进行梯度下降的计算，这叫做小批量随机梯度下降。<br />在每次迭代中，我们首先随机抽样一个小批量![](https://cdn.nlark.com/yuque/__latex/9e0b92d19bdf738dc2a21b6f447fad1f.svg#card=math&code=%5Cmathcal%7BB%7D%0A&id=unvfP)， 它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数学习率![](https://cdn.nlark.com/yuque/__latex/7483c6745bb07f292eba02b3a9b55c26.svg#card=math&code=%5Ceta&id=wpYDI)，并从当前参数的值中减掉。<br />![](https://cdn.nlark.com/yuque/__latex/245075027c4be840f01e2c40dbb7cf75.svg#card=math&code=%5Cbegin%7Bsplit%7D%5Cbegin%7Baligned%7D%20%5Cmathbf%7Bw%7D%20%26%5Cleftarrow%20%5Cmathbf%7Bw%7D%20-%20%20%20%5Cfrac%7B%5Ceta%7D%7B%7C%5Cmathcal%7BB%7D%7C%7D%20%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BB%7D%7D%20%5Cpartial_%7B%5Cmathbf%7Bw%7D%7D%20l%5E%7B%28i%29%7D%28%5Cmathbf%7Bw%7D%2C%20b%29%20%3D%20%5Cmathbf%7Bw%7D%20-%20%5Cfrac%7B%5Ceta%7D%7B%7C%5Cmathcal%7BB%7D%7C%7D%20%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BB%7D%7D%20%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%20%5Cleft%28%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%20%2B%20b%20-%20y%5E%7B%28i%29%7D%5Cright%29%2C%5C%5C%20b%20%26%5Cleftarrow%20b%20-%20%20%5Cfrac%7B%5Ceta%7D%7B%7C%5Cmathcal%7BB%7D%7C%7D%20%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BB%7D%7D%20%5Cpartial_b%20l%5E%7B%28i%29%7D%28%5Cmathbf%7Bw%7D%2C%20b%29%20%20%3D%20b%20-%20%5Cfrac%7B%5Ceta%7D%7B%7C%5Cmathcal%7BB%7D%7C%7D%20%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BB%7D%7D%20%5Cleft%28%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%20%2B%20b%20-%20y%5E%7B%28i%29%7D%5Cright%29.%20%5Cend%7Baligned%7D%5Cend%7Bsplit%7D&id=X1fcb)<br />批量大小和学习率的值通常是手动预先指定，而不是通过模型训练得到的。 这些可以调整但不在训练过程中更新的参数称为_超参数_（hyperparameter）。 _调参_（hyperparameter tuning）是选择超参数的过程。 超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的_验证数据集_（validation dataset）上评估得到的。<br />对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为_泛化_（generalization）。<br />矢量化计算可以使计算时间减少数量级倍。<br />正态分布也叫做高斯分布，概率密度函数为：<br />![](https://cdn.nlark.com/yuque/__latex/b95e40417cd4b7c8c40203326ceb14b5.svg#card=math&code=p%28x%29%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%20%5Cpi%20%5Csigma%5E2%7D%7D%20%5Cexp%5Cleft%28-%5Cfrac%7B1%7D%7B2%20%5Csigma%5E2%7D%20%28x%20-%20%5Cmu%29%5E2%5Cright%29.&id=BVPDE)<br />**似然函数**是概率的逆过程，和最小二乘法求参数一样，都是利用已有的数据点样本去求得满足该数据分布的参数。<br />均方误差损失函数（简称均方损失）可以用于线性回归的一个原因是： 我们假设了观测中包含噪声，其中噪声服从正态分布。 噪声正态分布如下式:<br />![](https://cdn.nlark.com/yuque/__latex/92f505df2ce4cfe1d4bda311595e4f43.svg#card=math&code=y%20%3D%20%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%20%2B%20b%20%2B%20%5Cepsilon%2C&id=FSIKw)<br />其中噪声服从正态分布：![](https://cdn.nlark.com/yuque/__latex/0aba72d7b8fb8d340809d13382148dbd.svg#card=math&code=%5Cepsilon%20%5Csim%20%5Cmathcal%7BN%7D%280%2C%20%5Csigma%5E2%29&id=dzeYs)<br />那么通过给定 x 观测到特定 y 的**似然（likehood）**为：<br />![](https://cdn.nlark.com/yuque/__latex/75ae8f6c757fcfa2e0091761615cfb8b.svg#card=math&code=P%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%20%5Cpi%20%5Csigma%5E2%7D%7D%20%5Cexp%5Cleft%28-%5Cfrac%7B1%7D%7B2%20%5Csigma%5E2%7D%20%28y%20-%20%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%20-%20b%29%5E2%5Cright%29.&id=TXvAL)<br />因为 x 是给定的，所以 y 的分布就是在噪声的基础之上加上了一个常数，也就是说 y 的分布是噪声的正态分布加上常数![](https://cdn.nlark.com/yuque/__latex/4a5935eb6e6a5a2e85fb1096106a3ef1.svg#card=math&code=%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%20%2B%20b%20&id=xJRlW)，那么 y 的方差不会改变，均值从 0 变为了![](https://cdn.nlark.com/yuque/__latex/4a5935eb6e6a5a2e85fb1096106a3ef1.svg#card=math&code=%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%20%2B%20b%20&id=Ccqa5)，所以 y 的概率分布也就变成了上式，因为方差和噪声的方差是一样的，加上常数不会改变方差。<br />![](https://cdn.nlark.com/yuque/__latex/e680478f183b56bdfe4a7a4f90c82b3b.svg#card=math&code=P%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%20%5Cpi%20%5Csigma%5E2%7D%7D%20%5Cexp%5Cleft%28-%5Cfrac%7B1%7D%7B2%20%5Csigma%5E2%7D%20%28y%20-%20%28%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%20%2B%20b%29%29%5E2%5Cright%29.&id=f7NIh)<br />根据极大似然估计法选择的估计量称为_极大似然估计量_。由于乘积很难计算，通常通过取对数来简化计算过程。<br />![](https://cdn.nlark.com/yuque/__latex/91f31710fca8419d44c98e991576d5ed.svg#card=math&code=-%5Clog%20P%28%5Cmathbf%20y%20%5Cmid%20%5Cmathbf%20X%29%20%3D%20%5Csum_%7Bi%3D1%7D%5En%20%5Cfrac%7B1%7D%7B2%7D%20%5Clog%282%20%5Cpi%20%5Csigma%5E2%29%20%2B%20%5Cfrac%7B1%7D%7B2%20%5Csigma%5E2%7D%20%5Cleft%28y%5E%7B%28i%29%7D%20-%20%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%20-%20b%5Cright%29%5E2.&id=Vzbhl)<br />现在我们只需要假设![](https://cdn.nlark.com/yuque/__latex/788df1ba344b3092def7590d1be6b4d4.svg#card=math&code=%5Csigma&id=CcUBL)是某个固定常数就可以忽略第一项， 因为第一项不依赖于w和b。 现在第二项除了常数![](https://cdn.nlark.com/yuque/__latex/281ef8416347422aa501052fa5e6fa24.svg#card=math&code=%5Cfrac%7B1%7D%7B%5Csigma%5E2%7D&id=ZluMo)外，其余部分和前面介绍的均方误差是一样的。 幸运的是，上面式子的解并不依赖于![](https://cdn.nlark.com/yuque/__latex/788df1ba344b3092def7590d1be6b4d4.svg#card=math&code=%5Csigma&id=lnqw5)。 因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1722497389351-aa5023bb-f8cd-401c-989e-515e6c4e8813.svg#clientId=uae00294d-1cae-4&from=paste&id=u19b0b6fe&originHeight=117&originWidth=336&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u9fddffb5-1791-4e81-82fb-40a978bbc5c&title=)<br />线性回归是一个单层神经网络<br /> 由于模型重点在发生计算的地方，所以通常我们在计算层数时**不考虑输入层**。<br />**小结：**

- 机器学习模型中的关键要素是训练数据、损失函数、优化算法，还有模型本身。
- 矢量化使数学表达上更简洁，同时运行的更快。
- 最小化目标函数和执行极大似然估计等价。
- 线性回归模型也是一个简单的神经网络。
<a name="oDVyH"></a>
#### 线性回归的代码实现
线性回归的模型是单层网络架构，只有一个全连接层，所以模型可以定义为：
```
# nn是神经网络的缩写
from torch import nn

net = nn.Sequential(nn.Linear(2, 1))
```
可以通过 net[0] 访问第一层，然后使用`weight.data`和`bias.data`方法访问参数。 我们还可以使用替换方法`normal_`和`fill_`来重写参数值。

```
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
```
损失函数一般使用均方误差，即 L2 范数，计算所有样本损失的均值；
```
loss = nn.MSELoss()
```
训练过程是不停的获取一个小批量的数据，然后对这个小批量的数据进行以下三步计算：

- 调用 net（X） 生成预测值并计算损失值，即前向传播；
- 通过反向传播计算梯度；
- 通过调用优化器来更新模型的参数，优化器包括随机梯度下降、Adam 等；
```
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad()
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')
```
<a name="vptAR"></a>
#### softmax 回归的基础知识
监督学习中的估计不只有预测某个值，即使是预测估计某个值，也不是只有最小化平方误差这种线性回归模型；softamax 主要用来解决**分类**的问题。<br />![](https://cdn.nlark.com/yuque/0/2024/svg/39264174/1722859354988-35564838-e5fe-4e68-8d64-217196a58193.svg#clientId=uca7b1ab2-0b15-4&from=paste&id=ue025d8b9&originHeight=117&originWidth=351&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ubc290fd4-def3-4684-b03b-5e1cfb73075&title=)<br />softmax 是一个单层的神经网络模型，是一个线性模型，输入和输出之间是仿射变换<br />分类问题中不同的类别之间没有自然的排序顺序，即不同的类别在排序时不能简单地按照 1，2，3 这种自然数进行排序，所以**独热编码（one hot）**用来表示分类数据。独热编码是一个向量，向量的大小和类别的数量相同，对应的元素为 1，其余的元素为 0，即![](https://cdn.nlark.com/yuque/__latex/ab461a05402bc604ffde2aeb247d3b62.svg#card=math&code=%281%2C%200%2C%200%29&id=EmSnQ)表示猫，![](https://cdn.nlark.com/yuque/__latex/7fcdf187e08b14b53ca03de9ad7615ba.svg#card=math&code=%280%2C%201%2C%200%29&id=vusoi)表示鸡，![](https://cdn.nlark.com/yuque/__latex/11de25379c4079ae8493de2cd3d59622.svg#card=math&code=%280%2C%200%2C%201%29&id=iNuHh)表示狗这种，![](https://cdn.nlark.com/yuque/__latex/cdc6d494e02ff59c5e37a5554ddcafd5.svg#card=math&code=y%20%5Cin%20%5C%7B%281%2C%200%2C%200%29%2C%20%280%2C%201%2C%200%29%2C%20%280%2C%200%2C%201%29%5C%7D.&id=ChFI5)<br />为了将所有预测的分类的概率之和限制为 1，并且保证预测的概率都是非负的（因为概率不可能小于 0），在这里使用指数函数并进行正则化，输出的概率 o 首先使用指数函数，将其转化为非负数，然后再将其除以所有预测概率之和来保证最后输出的概率在 0-1 之间。值得注意的是 **softmax 仍然是线性模型**。<br />![](https://cdn.nlark.com/yuque/__latex/568cfeb9eb9c2c20df7fd36e989227af.svg#card=math&code=%5Chat%7B%5Cmathbf%7By%7D%7D%20%3D%20%5Cmathrm%7Bsoftmax%7D%28%5Cmathbf%7Bo%7D%29%20%5Cquad%20%5Ctextrm%7Bwhere%7D%5Cquad%20%5Chat%7By%7D_i%20%3D%20%5Cfrac%7B%5Cexp%28o_i%29%7D%7B%5Csum_j%20%5Cexp%28o_j%29%7D.&id=S27oC)<br />**损失函数**<br />为了更新模型的参数，softmax 中依然是基于最大似然估计来更新模型的参数。对于任意给定的输入 x，估计的每个类的条件概率<br />![](https://cdn.nlark.com/yuque/__latex/54f5af76eb189ff475947a7522c25546.svg#card=math&code=P%28%5Cmathbf%7BY%7D%20%5Cmid%20%5Cmathbf%7BX%7D%29%20%3D%20%5Cprod_%7Bi%3D1%7D%5En%20P%28%5Cmathbf%7By%7D%5E%7B%28i%29%7D%20%5Cmid%20%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%29.&id=joBCc)<br />![](https://cdn.nlark.com/yuque/__latex/442b3c4b660b1a8441b125a5d8b27772.svg#card=math&code=-%5Clog%20P%28%5Cmathbf%7BY%7D%20%5Cmid%20%5Cmathbf%7BX%7D%29%20%3D%20%5Csum_%7Bi%3D1%7D%5En%20-%5Clog%20P%28%5Cmathbf%7By%7D%5E%7B%28i%29%7D%20%5Cmid%20%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%29%0A%3D%20%5Csum_%7Bi%3D1%7D%5En%20l%28%5Cmathbf%7By%7D%5E%7B%28i%29%7D%2C%20%5Chat%7B%5Cmathbf%7By%7D%7D%5E%7B%28i%29%7D%29%2C&id=XbPXl)<br />因为标签是 one hot 编码，所以只有对应的类别是 1，其余全为 0，所以这个条件概率实际上就是![](https://cdn.nlark.com/yuque/__latex/237bd4109450a26f96e85fc5fb813597.svg#card=math&code=%5Chat%7B%5Cmathbf%7By_j%7D%7D&id=KYT6P),所以最后的损失函数如下所示就是交叉熵。<br />![](https://cdn.nlark.com/yuque/__latex/9ea68b84c8d13a7ae867d4bfc400212f.svg#card=math&code=l%28%5Cmathbf%7By%7D%2C%20%5Chat%7B%5Cmathbf%7By%7D%7D%29%20%3D%20-%20%5Csum_%7Bj%3D1%7D%5Eq%20y_j%20%5Clog%20%5Chat%7By%7D_j.&id=bCrpZ)<br />为了对交叉熵损失函数理解的更深一些，将 softmax 函数带入交叉熵损失函数中得到：<br />![](https://cdn.nlark.com/yuque/__latex/8294baa696e170c55fbe4bdc9a1b5ee7.svg#card=math&code=%5Cbegin%7Bsplit%7D%5Cbegin%7Baligned%7D%0Al%28%5Cmathbf%7By%7D%2C%20%5Chat%7B%5Cmathbf%7By%7D%7D%29%20%26%3D%20%20-%20%5Csum_%7Bj%3D1%7D%5Eq%20y_j%20%5Clog%20%5Cfrac%7B%5Cexp%28o_j%29%7D%7B%5Csum_%7Bk%3D1%7D%5Eq%20%5Cexp%28o_k%29%7D%20%5C%5C%0A%26%3D%20%5Csum_%7Bj%3D1%7D%5Eq%20y_j%20%5Clog%20%5Csum_%7Bk%3D1%7D%5Eq%20%5Cexp%28o_k%29%20-%20%5Csum_%7Bj%3D1%7D%5Eq%20y_j%20o_j%20%5C%5C%0A%26%3D%20%5Clog%20%5Csum_%7Bk%3D1%7D%5Eq%20%5Cexp%28o_k%29%20-%20%5Csum_%7Bj%3D1%7D%5Eq%20y_j%20o_j.%0A%5Cend%7Baligned%7D%5Cend%7Bsplit%7D&id=QFdZl)<br />然后对 oj 进行求导得到下式，对于第一项求导，由于是复合函数，所以分子是各项之和，而分子是对这个和求导，由于是 one hot 编码，所以只有对应的 oj 才为 1，其余项对于 oj 来说全是 0，所以分支只有一项 exp(oj)，对于第二项只所以不能把 yj 去掉，是因为 yj 和 oj 是联合在一起的，用于表示只有在第 j 项时才有 oj，因为 yj 就是 1。交叉熵损失函数求导的结果和在回归模型中求导的结果是类似的，都是可以转化为交叉熵的损失函数的。<br />![](https://cdn.nlark.com/yuque/__latex/6d3fd6ae1eddc20a1cfdf861d2347a7e.svg#card=math&code=%5Cpartial_%7Bo_j%7D%20l%28%5Cmathbf%7By%7D%2C%20%5Chat%7B%5Cmathbf%7By%7D%7D%29%20%3D%20%5Cfrac%7B%5Cexp%28o_j%29%7D%7B%5Csum_%7Bk%3D1%7D%5Eq%20%5Cexp%28o_k%29%7D%20-%20y_j%20%3D%20%5Cmathrm%7Bsoftmax%7D%28%5Cmathbf%7Bo%7D%29_j%20-%20y_j.&id=aMgHU)<br />需要注意的是，交叉熵损失函数在计算的时候可能会由于 oj 比较大，导致计算的指数超过范围，产生溢出，所以在计算的时候可以将输出的 oj 减去最大的 oj 然后再进行 softmax 计算，这样所有的 oj 都是小于等于 0 的，不会产生上溢的风险；<br />![](https://cdn.nlark.com/yuque/__latex/902dc725e02dfcf8eecd2f1e2e7f1f3b.svg#card=math&code=%5Chat%20y_j%20%3D%20%5Cfrac%7B%5Cexp%20o_j%7D%7B%5Csum_k%20%5Cexp%20o_k%7D%20%3D%0A%5Cfrac%7B%5Cexp%28o_j%20-%20%5Cbar%7Bo%7D%29%20%5Cexp%20%5Cbar%7Bo%7D%7D%7B%5Csum_k%20%5Cexp%20%28o_k%20-%20%5Cbar%7Bo%7D%29%20%5Cexp%20%5Cbar%7Bo%7D%7D%20%3D%0A%5Cfrac%7B%5Cexp%28o_j%20-%20%5Cbar%7Bo%7D%29%7D%7B%5Csum_k%20%5Cexp%20%28o_k%20-%20%5Cbar%7Bo%7D%29%7D.&id=CLFKQ)<br />为了避免下溢，我们采用对数交叉熵损失函数：<br />![](https://cdn.nlark.com/yuque/__latex/1af5b293ad0b0165355bb5027571719b.svg#card=math&code=%5Clog%20%5Chat%7By%7D_j%20%3D%0A%5Clog%20%5Cfrac%7B%5Cexp%28o_j%20-%20%5Cbar%7Bo%7D%29%7D%7B%5Csum_k%20%5Cexp%20%28o_k%20-%20%5Cbar%7Bo%7D%29%7D%20%3D%0Ao_j%20-%20%5Cbar%7Bo%7D%20-%20%5Clog%20%5Csum_k%20%5Cexp%20%28o_k%20-%20%5Cbar%7Bo%7D%29.&id=q1IBG)<br />**信息论基础知识**<br />一个事件包含的信息量为：<br />![](https://cdn.nlark.com/yuque/__latex/03821c413bbdf44192aa59c1f031df97.svg#card=math&code=%5Clog%20%5Cfrac%7B1%7D%7BP%28j%29%7D%20%3D%20-%5Clog%20P%28j%29&id=bSJVD)<br />信息论的主要核心是量化数据中包含多少信息量，这决定了我们最少采用多少数据才能不失真的传达某个信息，因此对于一个事件集的分布 P，它的熵为下式所示，表示对所有的单个事件的自信息求期望值：<br />![](https://cdn.nlark.com/yuque/__latex/225922d9921cb60f219cbe5677e8e769.svg#card=math&code=H%5BP%5D%20%3D%20%5Csum_j%20-%20P%28j%29%20%5Clog%20P%28j%29.&id=zbYGT)<br />这表明为了编码从分布 P 中随机抽取数据，至少需要 H(P)个 nat 来进行编码吗，nat 是以底数 e 进行计算的，而 bit 是以底数为 2 进行计算的，因此 1nat 等于![](https://cdn.nlark.com/yuque/__latex/22d032444133c85023aba994b0a46c01.svg#card=math&code=%5Cfrac%7B1%7D%7B%5Clog%282%29%7D%20%5Capprox%201.44&id=KOsYq)比特。<br />编码是为了预测这一条数据流中下一个数据是什么，比如说有一条相同的数据流，每个数据都是相同的，那么这条数据流包含的信息就特别少。<br />交叉熵是指我们想要知道 p 分布的信息，但是 p 分布是未知的，即 p 是真实数据的分布，我们通过无法得知真实数据的概率分布；我们训练所用的数据集是采样或者其他方式获得的概率分布 q，这两个分布不是相同的，为了衡量训练得到的分布和真实分布之间的差异，采用交叉熵来进行量化：<br />![](https://cdn.nlark.com/yuque/__latex/06cca99004343f2994983cdcc2e71a0a.svg#card=math&code=H%28P%2C%20Q%29%20%5Cstackrel%7B%5Ctextrm%7Bdef%7D%7D%7B%3D%7D%20%5Csum_j%20-%20P%28j%29%20%5Clog%20Q%28j%29&id=e7pEi)<br />**泛化问题**<br />解决以 95%的置信度得出结论，估计在测试集上的测试误差 ϵD(f) 与在真实数据集上的真实误差 ϵ(f) 之间的距离 t 不超过 0.01 所需的最小数据集 n 的大小。这个计算出来的数值比真实所需的数据集的数量要大一些，但是可以作为一个大致的评估标准，表明测试集需要多少数据进行测试所达到的误差才能和，在泛化或者迁移到真实的数据集之后，所产生的真实误差相同或者类似这个事件，具有多少的置信度。<br />![](https://cdn.nlark.com/yuque/__latex/4fac5bf653dccd1a610bd242ad002846.svg#card=math&code=P%28%5Cepsilon_%5Cmathcal%7BD%7D%28f%29%20-%20%5Cepsilon%28f%29%20%5Cgeq%20t%29%20%3C%20%5Cexp%5Cleft%28%20-%202n%20t%5E2%20%5Cright%29%3C0.01.&id=UrJ5o)<br />有时候我们训练的数据是从某一个分布采样的，但是测试的数据是从不同的分布中采样得到的，如果不知道测试集中的分布和训练数据集的分布之间的关系，那么训练得到的分类器将不会是稳定的。<br />为了解决上述问题，我们可以采用协变量偏移，即尽管输入的分布可能会随着时间改变，但是条件分布![](https://cdn.nlark.com/yuque/__latex/39b7aa6aa4d2d7371c54d64e2704b3ba.svg#card=math&code=P%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29&id=PAMHo)不会变化，我们可以不引入因果关系来推理分布偏移。另外还有标签迁移和概念迁移；<br />**模型偏差矫正**<br />我们想要估计 p(x)的概率分布，但是训练的数据是从 q(x)中采样的，为了减少这两个概率分布之间的偏差，可以采用下式进行矫正，其中有一点需要注意的是条件分布不会改变![](https://cdn.nlark.com/yuque/__latex/fa8d5e82de9d1034e88edb5899c51182.svg#card=math&code=p%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29%20%3D%20q%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29&id=SxY8G)：<br />![](https://cdn.nlark.com/yuque/__latex/c9e6cc850f243fe6fea2a09ef584cc27.svg#card=math&code=%5Cbegin%7Baligned%7D%0A%5Cint%5Cint%20l%28f%28%5Cmathbf%7Bx%7D%29%2C%20y%29%20p%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29p%28%5Cmathbf%7Bx%7D%29%20%5C%3Bd%5Cmathbf%7Bx%7Ddy%20%3D%0A%5Cint%5Cint%20l%28f%28%5Cmathbf%7Bx%7D%29%2C%20y%29%20q%28y%20%5Cmid%20%5Cmathbf%7Bx%7D%29q%28%5Cmathbf%7Bx%7D%29%5Cfrac%7Bp%28%5Cmathbf%7Bx%7D%29%7D%7Bq%28%5Cmathbf%7Bx%7D%29%7D%20%5C%3Bd%5Cmathbf%7Bx%7Ddy.%0A%5Cend%7Baligned%7D&id=lXfVk)<br />这相当于通过正确分布和错误分布之间的概率之比来对每个数据样本进行加权，在 PPO 中叫做重要性采样<br />![](https://cdn.nlark.com/yuque/__latex/49002c4aca7e7d84c8f329d12609d9a5.svg#card=math&code=%5Cbeta_i%20%5Cstackrel%7B%5Ctextrm%7Bdef%7D%7D%7B%3D%7D%20%5Cfrac%7Bp%28%5Cmathbf%7Bx%7D_i%29%7D%7Bq%28%5Cmathbf%7Bx%7D_i%29%7D.&id=Gbi51)即使 q（x）和 p(x)分布不一样，但是可以通过这个比值来校正不一样数据的权重，即更关心 p(x)分布下的数据。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/39264174/1722911996540-a4b8b10d-b20a-4769-b138-f1fb6f0b8e03.png#averageHue=%23f3fbf7&clientId=uca7b1ab2-0b15-4&from=paste&id=u8298fcad&originHeight=3490&originWidth=5977&originalType=url&ratio=1&rotation=0&showTitle=false&size=3155019&status=done&style=none&taskId=ue6c5ac5f-ad5f-4915-9c85-4a9afffdef0&title=)<br />**总结**<br />在许多情况下，训练集和测试集来自不同的分布。这被称为分布偏移。风险是指从数据的真实分布中抽取的数据总体的损失期望。然而，整个数据集通常不可用。经验风险是通过近似风险来计算**训练集数据**上的平均损失。实践中，我们进行经验风险最小化。<br />在相应的假设下，可以在测试时检测和纠正协变量和标签偏移。未能考虑这种偏见在测试时可能会变得问题重重。在某些情况下，环境可能会记住自动化操作并以出乎意料的方式响应。在构建模型时，我们必须考虑到这种可能性，并继续监控实时系统，保持开放的态度，以防我们的模型和环境以未预见的方式交织在一起。
<a name="uILA8"></a>
### transformer
李宏毅讲解的 transformer[Transformer - YouTube](https://www.youtube.com/watch?v=ugWDIIOHtPA&list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&index=61)

<a name="VC7CX"></a>
# 多刚体动力学

